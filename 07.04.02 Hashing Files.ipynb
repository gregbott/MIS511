{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing Files to Find Duplicates\n",
    "\n",
    "TODO: comment on each function\n",
    "TODO: Test this code (source: dupFinder.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived from sources: https://www.pythoncentral.io/finding-duplicate-files-with-python/\n",
    "import os, sys, shutil\n",
    "import hashlib, random\n",
    "\n",
    "# Folder in which to place duplicate files\n",
    "dupefolder = \"c:\\\\bts\\\\destinationfolder\\\\\"\n",
    "folders = [\"c:\\\\bts\\\\sourcefolder\"]\n",
    "\n",
    "# Flag to move files or only list them. True = move files; False = list, don't move.\n",
    "MOVEFILES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash function\n",
    "* Explain why this is done in blocks\n",
    "* Explain how update function works\n",
    "* Explain why md5 and what md5 is and the potential drawbacks to using md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash Function\n",
    "def hashfile(path, blocksize=65536):\n",
    "    afile = open(path, 'rb')\n",
    "    hasher = hashlib.md5()\n",
    "    buf = afile.read(blocksize)\n",
    "    while len(buf) > 0:\n",
    "        hasher.update(buf)\n",
    "        buf = afile.read(blocksize)\n",
    "    afile.close()\n",
    "    return hasher.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Dictionary function\n",
    "# Joins two dictionaries\n",
    "def joinDicts(dict1, dict2):\n",
    "    for key in dict2.keys():\n",
    "        if key in dict1:\n",
    "            dict1[key] = dict1[key] + dict2[key]\n",
    "        else:\n",
    "            dict1[key] = dict2[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(dict1):\n",
    "    results = list(filter(lambda x: len(x) > 1, dict1.values()))\n",
    "    if len(results) > 0:\n",
    "        print('Duplicates Found:')\n",
    "        print('The following files are identical. The name could differ, but the content is identical')\n",
    "        print('___________________')\n",
    "        for result in results:\n",
    "            for subresult in result:\n",
    "                print('\\t\\t%s' % subresult)\n",
    "            print('___________________')\n",
    "\n",
    "    else:\n",
    "        print('No duplicate files found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveFile(path, dupefolder, filename):\n",
    "    \n",
    "    # move file    \n",
    "    shutil.move(path, dupefolder + filename)\n",
    "    print(\"**MOVING**\",path, dupefolder+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDup(parentFolder):\n",
    "    # Dups in format {hash:[names]}\n",
    "    dups = {}\n",
    "    for dirName, subdirs, fileList in os.walk(parentFolder):\n",
    "        print('Scanning %s...' % dirName)\n",
    "        for filename in fileList:\n",
    "            # Get the path to the file\n",
    "            path = os.path.join(dirName, filename)\n",
    "            # Calculate hash\n",
    "            file_hash = hashfile(path)\n",
    "            \n",
    "            # **** replace lines below with call to moveFile function ****\n",
    "            \n",
    "            # Add or append the file path\n",
    "            if MOVEFILES and file_hash in dups:\n",
    "                if filename in fileList:\n",
    "                    \n",
    "                    # Use \"old_file\" for readability\n",
    "                    old_file = path\n",
    "                    \n",
    "                    # Prefix dupe and random 5-digit number to avoid error if file exists\n",
    "                    new_filename = \"Dupe\" + str(random.randint(10000,99999)) + \"_\" + filename\n",
    "                    new_file = os.path.join(dirName, new_filename)\n",
    "                    \n",
    "                    #Debug\n",
    "                    #print(\"files: \" + path, new_file)\n",
    "                    \n",
    "                    #Use os.rename b/c it won't orphan a file like shutil can\n",
    "                    os.rename(old_file, new_file)\n",
    "                    \n",
    "                    #Update path and file name for moveFile function\n",
    "                    path = new_file\n",
    "                    filename = new_filename\n",
    "                    \n",
    "                dups[file_hash].append(path)\n",
    "                moveFile(path, dupefolder, filename)\n",
    "            else:\n",
    "                dups[file_hash] = [path]\n",
    "    return dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = {}\n",
    "\n",
    "for i in folders:\n",
    "    # Iterate the folders given\n",
    "    if os.path.exists(i):\n",
    "        # Find the duplicated files and append them to the dups\n",
    "        joinDicts(dups, findDup(i))\n",
    "    else:\n",
    "        print('%s is not a valid path, please verify' % i)\n",
    "        sys.exit()\n",
    "printResults(dups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
